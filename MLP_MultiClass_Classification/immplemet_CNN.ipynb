{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "# 1. Configurer TensorFlow pour limiter l'utilisation de la mémoire\n",
        "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True) if tf.config.list_physical_devices('GPU') else None\n",
        "\n",
        "# 2. Charger et préparer les données MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Préparation pour le CNN simple (images 28x28x1)\n",
        "x_train_cnn = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test_cnn = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Préparation pour VGG16 (images 48x48x3)\n",
        "x_train_vgg = np.repeat(x_train[..., np.newaxis], 3, axis=-1)\n",
        "x_test_vgg = np.repeat(x_test[..., np.newaxis], 3, axis=-1)\n",
        "\n",
        "# 3. Réduire le jeu d'entraînement pour VGG16 (10 000 images) AVANT resize\n",
        "train_indices = np.random.choice(len(x_train_vgg), 10000, replace=False)\n",
        "x_train_vgg = x_train_vgg[train_indices]\n",
        "y_train_cat_vgg = to_categorical(y_train[train_indices], 10)\n",
        "\n",
        "# Redimensionner après indexation\n",
        "x_train_vgg = tf.image.resize(x_train_vgg, [48, 48]) / 255.0\n",
        "x_test_vgg = tf.image.resize(x_test_vgg, [48, 48]) / 255.0\n",
        "\n",
        "# Encodage one-hot des étiquettes pour le test\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# 4. Créer des pipelines tf.data avec petit buffer\n",
        "train_dataset_cnn = tf.data.Dataset.from_tensor_slices((x_train_cnn, to_categorical(y_train, 10))).batch(32).prefetch(1)\n",
        "test_dataset_cnn = tf.data.Dataset.from_tensor_slices((x_test_cnn, y_test_cat)).batch(32).prefetch(1)\n",
        "\n",
        "train_dataset_vgg = tf.data.Dataset.from_tensor_slices((x_train_vgg, y_train_cat_vgg)).batch(8).prefetch(1)\n",
        "test_dataset_vgg = tf.data.Dataset.from_tensor_slices((x_test_vgg, y_test_cat)).batch(8).prefetch(1)\n",
        "\n",
        "# Libérer la mémoire\n",
        "del x_train, x_test, x_train_cnn, x_test_cnn, x_train_vgg, x_test_vgg, y_train, y_test, y_train_cat_vgg, y_test_cat\n",
        "gc.collect()\n",
        "\n",
        "# 5. Implémenter un CNN simple\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiler et entraîner le CNN\n",
        "cnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "print(\"Entraînement du CNN simple...\")\n",
        "cnn_model.fit(train_dataset_cnn, epochs=5, validation_data=test_dataset_cnn)\n",
        "\n",
        "# Libérer la mémoire après le CNN\n",
        "del cnn_model\n",
        "gc.collect()\n",
        "\n",
        "# 6. Transfert d'apprentissage avec VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "vgg_model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiler et entraîner VGG16\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "print(\"Entraînement du modèle VGG16 (Transfer Learning)...\")\n",
        "vgg_model.fit(train_dataset_vgg, epochs=3, validation_data=test_dataset_vgg)"
      ],
      "metadata": {
        "id": "PDdDeehmMPN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c107dd0-2fd6-4f7e-bea2-3387346c3f3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entraînement du CNN simple...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 32ms/step - accuracy: 0.9149 - loss: 0.2858 - val_accuracy: 0.9749 - val_loss: 0.0701\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9842 - loss: 0.0514 - val_accuracy: 0.9868 - val_loss: 0.0424\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 35ms/step - accuracy: 0.9898 - loss: 0.0332 - val_accuracy: 0.9888 - val_loss: 0.0335\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 31ms/step - accuracy: 0.9931 - loss: 0.0212 - val_accuracy: 0.9898 - val_loss: 0.0322\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 32ms/step - accuracy: 0.9956 - loss: 0.0139 - val_accuracy: 0.9896 - val_loss: 0.0378\n",
            "Entraînement du modèle VGG16 (Transfer Learning)...\n",
            "Epoch 1/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 459ms/step - accuracy: 0.4401 - loss: 1.8854 - val_accuracy: 0.7781 - val_loss: 1.0484\n",
            "Epoch 2/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 456ms/step - accuracy: 0.8153 - loss: 0.9147 - val_accuracy: 0.8447 - val_loss: 0.6839\n",
            "Epoch 3/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 488ms/step - accuracy: 0.8583 - loss: 0.6236 - val_accuracy: 0.8747 - val_loss: 0.5268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fae96b55b90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Transfert d'apprentissage avec ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "resnet_model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiler et entraîner ResNet50\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "print(\"Entraînement du modèle ResNet50 (Transfer Learning)...\")\n",
        "resnet_model.fit(train_dataset_vgg, epochs=3, validation_data=test_dataset_vgg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1VIB16e_WdJ",
        "outputId": "15c1c119-57fa-4e9f-859d-1ecc0007712a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entraînement du modèle ResNet50 (Transfer Learning)...\n",
            "Epoch 1/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 202ms/step - accuracy: 0.4773 - loss: 1.7362 - val_accuracy: 0.7518 - val_loss: 0.9500\n",
            "Epoch 2/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 198ms/step - accuracy: 0.7669 - loss: 0.8911 - val_accuracy: 0.8199 - val_loss: 0.6732\n",
            "Epoch 3/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 203ms/step - accuracy: 0.8190 - loss: 0.6715 - val_accuracy: 0.8516 - val_loss: 0.5449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fae9750a190>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}