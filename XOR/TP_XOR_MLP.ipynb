{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Démonstration de la dérivée de la fonction sigmoïde**\n",
    "\n",
    "On a\n",
    "\n",
    "$$\n",
    "\\sigma'(z) = \\left( \\frac{1}{1 + e^{-z}} \\right)'\n",
    "$$\n",
    "\n",
    "Et on a :\n",
    "\n",
    "$$\n",
    "\\left(\\frac{1}{u(z)}\\right)' = -\\frac{u'(z)}{(u(z))^2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Calculons $ u'(z) $:\n",
    "$ u(z) = 1 + e^{-z} \\quad \\Rightarrow \\quad u'(z) = -e^{-z} $\n",
    "\n",
    "Ainsi :\n",
    "\n",
    "$$\n",
    "\\sigma'(z) = -\\frac{-e^{-z}}{(1 + e^{-z})^2} = \\frac{e^{-z}}{(1 + e^{-z})^2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "donc :\n",
    "$$\n",
    "\\sigma'(z) =  \\left( \\frac{1}{1 + e^{-z}} \\right) \\left( \\frac{e^{-z}}{1 + e^{-z}} \\right) = \\left( \\frac{1}{1 + e^{-z}} \\right) \\left( \\frac{e^{-z} + 1 - 1}{1 + e^{-z}} \\right) = \\left( \\frac{1}{1 + e^{-z}} \\right) \\left( 1 - \\frac{ 1}{1 + e^{-z}} \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "Alors :\n",
    "\n",
    "$$\n",
    "\\sigma'(z) = \\sigma(z) \\cdot (1 - \\sigma(z))\n",
    "$$"
   ],
   "id": "a5364b8c9e558686"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Le role de seed :**\n",
    "\n",
    "La fonction **seed** permet d'avoir toujours les mêmes poids initiaux et donc de rendre l'entraînement du modèle prévisible et comparable."
   ],
   "id": "2b7008f3941c7cc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Les Démonstrations des derivees**\n",
    "\n",
    "On a :\n",
    "\n",
    "- $Z_1 = XW_1 + b_1$\n",
    "- $A_1 = \\sigma(Z_1)$\n",
    "- $Z_2 = A_1W_2 + b_2$\n",
    "- $A_2 = \\sigma(Z_2)$\n",
    "- $L = \\frac{1}{m} \\sum_{i=1}^m (y_i - A_{2,i})^2$\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## 1.Calculons  $\\frac{\\partial L}{\\partial Z_2}$ :\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} $$\n",
    "\n",
    "On a donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial}{\\partial A_2} \\left( \\frac{1}{m} \\sum_{i=1}^{m} (y_i - A_{2i})^2 \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\partial}{\\partial A_2} \\left( \\frac{1}{m} (y - A_2)^2 \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{-2}{m} (y - A_2) = \\frac{2}{m} (A_2 - y)\n",
    "$$\n",
    "\n",
    "Et :\n",
    "\n",
    "$$ A_2 = \\sigma(Z_2) \\quad \\Rightarrow \\quad \\frac{\\partial A_2}{\\partial Z_2} = \\sigma'(Z_2) $$\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} = \\frac{2}{m} (A_2 - y) \\sigma'(Z_2)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2.Calculons $\\frac{\\partial L}{\\partial W_2}$ :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial W_2}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Et on a :\n",
    "\n",
    "$$\n",
    "Z_2 = A_1 W_2 + b_2 \\Rightarrow \\frac{\\partial Z_2}{\\partial W_2} = A_1\n",
    "$$\n",
    "\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2} =  \\frac{\\partial L}{\\partial Z_2} \\cdot A_1\n",
    "\\Rightarrow\n",
    "\\frac{\\partial L}{\\partial W_2} = A_1^T \\cdot \\frac{\\partial L}{\\partial Z_2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3.Calculons $\\frac{\\partial L}{\\partial b_2}$ :\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial b_2}\n",
    "$$\n",
    "\n",
    "On a  :\n",
    "\n",
    "$$\n",
    "Z_2 = A_1W_2 + b_2 \\quad \\Rightarrow \\quad \\frac{\\partial Z_2}{\\partial b_2} = 1\n",
    "$$\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial Z_2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4.Calculons $\\frac{\\partial L}{\\partial Z_1}$ :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial A_1} \\cdot \\frac{\\partial A_1}{\\partial Z_1}\n",
    "$$\n",
    "\n",
    "On a :\n",
    "\n",
    "$$\n",
    "Z_2 = A_1W_2 + b_2 \\quad \\Rightarrow \\quad \\frac{\\partial Z_2}{\\partial A_1} = W_2\n",
    "$$\n",
    "\n",
    "Et :\n",
    "\n",
    "$$\n",
    "A_1 = \\sigma(Z_1) \\quad \\Rightarrow \\quad \\frac{\\partial A_1}{\\partial Z_1} = \\sigma'(Z_1)\n",
    "$$\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z_1} = \\left( \\frac{\\partial L}{\\partial Z_2} W_2^T \\right) \\sigma'(Z_1)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5.Calculons $\\frac{\\partial L}{\\partial W_1}$ :\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1} = \\frac{\\partial L}{\\partial Z_1} \\cdot \\frac{\\partial Z_1}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "On a :\n",
    "\n",
    "$$\n",
    "Z_1 = X W_1 + b_1 \\quad \\Rightarrow \\quad \\frac{\\partial Z_1}{\\partial W_1} = X\n",
    "$$\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1} =  \\frac{\\partial L}{\\partial Z_1} \\cdot X\n",
    "\\Rightarrow\n",
    "\\frac{\\partial L}{\\partial W_1} = X^T \\cdot \\frac{\\partial L}{\\partial Z_1}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 6.Calculons $\\frac{\\partial L}{\\partial b_1}$ :\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_1} = \\frac{\\partial L}{\\partial Z_1} \\times \\frac{\\partial Z_1}{\\partial b_1}\n",
    "$$\n",
    "\n",
    "On a :\n",
    "\n",
    "$$\n",
    "Z_1 = XW_1 + b_1 \\quad \\Rightarrow \\quad \\frac{\\partial Z_1}{\\partial b_1} = 1\n",
    "$$\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_1} = \\frac{\\partial L}{\\partial Z_1}\n",
    "$$\n",
    "\n",
    "---\n",
    "### Remarque :\n",
    "*(On transpose juste pour bien faire correspondre les dimensions.)*"
   ],
   "id": "f65b26c40a83fc62"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-06T07:45:50.299045Z",
     "start_time": "2025-05-06T07:45:50.257534Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T07:47:45.069859Z",
     "start_time": "2025-05-06T07:47:44.960332Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "# Etape 1 : Définir la fonction d’activation sigmoïde et sa dérivée\n",
    "def sigmoid(x):\n",
    "    result = 1 / (1 + np.exp(-x))  # Remplacez par la formule de la sigmoide\n",
    "    # Assertion : Verifier que les sorties sont entre 0 et 1\n",
    "    assert np.all((result >= 0) & (result <= 1)), \" Sigmoide shdould be between 0 and 1\"\n",
    "    return result\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    # A COMPLETER : Implementez la derivee de la sigmoide\n",
    "    s = sigmoid(x)\n",
    "    result = s * (1 - s)  # Remplacez None par la formule de la derivee\n",
    "    # Assertion : Verifier que la derivee est positive ou nulle\n",
    "    assert np.all(result >= 0), \"Dérivée de la sigmoïde doit être >= 0\"\n",
    "    # Assertion : Verifier que sigmoid_derivative (0) = 0.25\n",
    "    if np.isscalar(x) and x == 0:\n",
    "        assert np.isclose(result, 0.25), \"Dérivée de la sigmoïde à 0 doit être 0.25\"\n",
    "    return result"
   ],
   "id": "e7766a223aeb9d74"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Etape 2 : Définir la classe MLP\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01, seed=42):\n",
    "        # Fixer le seed pour la reproductibilit\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Initialisation des poids et biais\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # Assertions : Vérifier les dimensions\n",
    "        assert self.W1.shape == (input_size, hidden_size), \"Mauvaise dimension pour W1\"\n",
    "        assert self.b1.shape == (1, hidden_size), \"Mauvaise dimension pour b1\"\n",
    "        assert self.W2.shape == (hidden_size, output_size), \"Mauvaise dimension pour W2\"\n",
    "        assert self.b2.shape == (1, output_size), \"Mauvaise dimension pour b2\"\n",
    "\n",
    "    # Etape 3 : Propagation avant\n",
    "    def forward(self, X):\n",
    "        # A COMPLETER : Implementez la propagation avant\n",
    "        self.Z1 = X @ self.W1 + self.b1 # Calcul de Z1\n",
    "        self.A1 = sigmoid(self.Z1) # Activation de la couche c a c h e\n",
    "        self.Z2 = self.A1 @ self.W2 + self.b2 # Calcul de Z2\n",
    "        self.A2 = sigmoid(self.Z2) # Activation de la couche de sortie\n",
    "\n",
    "\n",
    "        # Assertions : Vérifier les dimensions\n",
    "        assert self.A1.shape == (X.shape[0], self.W1.shape[1]), \"Mauvaise dimension pour A1\"\n",
    "        assert self.A2.shape == (X.shape[0], self.W2.shape[1]), \"Mauvaise dimension pour A2\"\n",
    "        # Assertion : Verifier que A2 est entre 0 et 1\n",
    "        assert np.all((self.A2 >= 0) & (self.A2 <= 1)), \"Sortie A2 doit être entre 0 et 1\"\n",
    "\n",
    "        return self.A2\n",
    "\n",
    "    # Etape 4 : Calcul de la perte\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # A COMPLETER : Implementez le calcul de la perte (MSE)\n",
    "        loss = np.mean((y_true - y_pred) ** 2)   # Remplacez par la formule de la MSE\n",
    "        # Assertion : Verifier que la perte est positive ou nulle\n",
    "        assert loss >= 0, \"La perte doit être positive ou nulle\"\n",
    "\n",
    "        # Assertion : Verifier que la perte est 0 si y_true = y_pred\n",
    "        if np.array_equal(y_true, y_pred):\n",
    "            assert np.isclose(loss, 0), \"La perte doit être 0 si y_true = y_pred\"\n",
    "        return loss\n",
    "\n",
    "    # Etape 5 : Rétropropagation\n",
    "    def backward(self, X, y, y_pred):\n",
    "        m = X.shape[0]\n",
    "\n",
    "        #A COMPLETER : Implementez la retropropagation\n",
    "        # Gradient de la couche de sortie\n",
    "        dZ2 = 2 * (y_pred - y) * sigmoid_derivative(self.Z2) # Gradient de Z2\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / m # Gradient de W2\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m # Gradient de b2\n",
    "\n",
    "\n",
    "        # Gradient de la couche cachée\n",
    "        dA1 = np.dot(dZ2, self.W2.T) # Gradient de A2\n",
    "        dZ1 = dA1 * sigmoid_derivative(self.Z1) # Gradient de Z2\n",
    "        dW1 = np.dot(X.T, dZ1) / m # Gradient de W1\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m # Gradient de b1\n",
    "\n",
    "        # Assertions : Vérifier les dimensions des gradients\n",
    "        assert dW1.shape == self.W1.shape, \"Mauvaise dimension pour dW1\"\n",
    "        assert db1.shape == self.b1.shape, \"Mauvaise dimension pour db1\"\n",
    "        assert dW2.shape == self.W2.shape, \"Mauvaise dimension pour dW2\"\n",
    "        assert db2.shape == self.b2.shape, \"Mauvaise dimension pour db2\"\n",
    "\n",
    "        # Mise à jour des poids et biais\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "\n",
    "    # Etape 6 : Entrainement\n",
    "    def train(self, X, y, epochs):\n",
    "        prev_loss = float('inf')\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X) # Gradient de W1\n",
    "            loss = self.compute_loss(y, y_pred) # Gradient de W1\n",
    "            losses.append(loss)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss : {loss}\")\n",
    "            # Assertion : Verifier que la perte diminue (ou restestable )\n",
    "            assert loss <= prev_loss or np.isclose(loss, prev_loss), \"La perte doit diminuer ou rester stable\"\n",
    "            prev_loss = loss\n",
    "            self.backward(X, y, y_pred)\n",
    "        return losses"
   ],
   "id": "4a1d5f39772bdba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T07:48:33.307075Z",
     "start_time": "2025-05-06T07:48:27.363540Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss : 0.3649476107133394\n",
      "Epoch 100, Loss : 0.1928919957074199\n",
      "Epoch 200, Loss : 0.09664556560610649\n",
      "Epoch 300, Loss : 0.023658855385539062\n",
      "Epoch 400, Loss : 0.010014987706677105\n",
      "Epoch 500, Loss : 0.005884222428260522\n",
      "Epoch 600, Loss : 0.004043711444576799\n",
      "Epoch 700, Loss : 0.00303455056831694\n",
      "Epoch 800, Loss : 0.0024074240821965417\n",
      "Epoch 900, Loss : 0.001983974817043022\n",
      "Epoch 1000, Loss : 0.0016807243270178288\n",
      "Epoch 1100, Loss : 0.0014538329798140927\n",
      "Epoch 1200, Loss : 0.0012782362485055563\n",
      "Epoch 1300, Loss : 0.0011386375206094458\n",
      "Epoch 1400, Loss : 0.0010252061484952487\n",
      "Epoch 1500, Loss : 0.0009313535701143372\n",
      "Epoch 1600, Loss : 0.0008525080386895204\n",
      "Epoch 1700, Loss : 0.0007854031982233345\n",
      "Epoch 1800, Loss : 0.0007276464589801559\n",
      "Epoch 1900, Loss : 0.0006774471629266124\n",
      "Epoch 2000, Loss : 0.0006334397903537427\n",
      "Epoch 2100, Loss : 0.0005945657172072552\n",
      "Epoch 2200, Loss : 0.0005599921661835653\n",
      "Epoch 2300, Loss : 0.0005290554315046357\n",
      "Epoch 2400, Loss : 0.0005012203295795038\n",
      "Epoch 2500, Loss : 0.0004760507307065247\n",
      "Epoch 2600, Loss : 0.00045318780535904234\n",
      "Epoch 2700, Loss : 0.0004323337356041121\n",
      "Epoch 2800, Loss : 0.0004132393597813483\n",
      "Epoch 2900, Loss : 0.0003956946890656928\n",
      "Epoch 3000, Loss : 0.0003795215488292969\n",
      "Epoch 3100, Loss : 0.00036456781127285054\n",
      "Epoch 3200, Loss : 0.00035070283319330747\n",
      "Epoch 3300, Loss : 0.00033781381596792275\n",
      "Epoch 3400, Loss : 0.0003258028780795217\n",
      "Epoch 3500, Loss : 0.0003145846831341196\n",
      "Epoch 3600, Loss : 0.00030408450457164\n",
      "Epoch 3700, Loss : 0.0002942366363713764\n",
      "Epoch 3800, Loss : 0.0002849830799069882\n",
      "Epoch 3900, Loss : 0.0002762724527270792\n",
      "Epoch 4000, Loss : 0.00026805907684291383\n",
      "Epoch 4100, Loss : 0.00026030221310148634\n",
      "Epoch 4200, Loss : 0.0002529654151316946\n",
      "Epoch 4300, Loss : 0.00024601598169784686\n",
      "Epoch 4400, Loss : 0.000239424490460331\n",
      "Epoch 4500, Loss : 0.00023316439941060683\n",
      "Epoch 4600, Loss : 0.00022721170482658233\n",
      "Epoch 4700, Loss : 0.00022154464664192702\n",
      "Epoch 4800, Loss : 0.00021614345375802456\n",
      "Epoch 4900, Loss : 0.0002109901231398472\n",
      "Epoch 5000, Loss : 0.00020606822759632325\n",
      "Epoch 5100, Loss : 0.00020136274800488125\n",
      "Epoch 5200, Loss : 0.00019685992643961152\n",
      "Epoch 5300, Loss : 0.00019254713723539302\n",
      "Epoch 5400, Loss : 0.00018841277349115174\n",
      "Epoch 5500, Loss : 0.00018444614690390094\n",
      "Epoch 5600, Loss : 0.00018063739914730216\n",
      "Epoch 5700, Loss : 0.00017697742327619676\n",
      "Epoch 5800, Loss : 0.0001734577938621305\n",
      "Epoch 5900, Loss : 0.00017007070475214786\n",
      "Epoch 6000, Loss : 0.00016680891350053943\n",
      "Epoch 6100, Loss : 0.00016366569165592035\n",
      "Epoch 6200, Loss : 0.00016063478019830713\n",
      "Epoch 6300, Loss : 0.000157710349516085\n",
      "Epoch 6400, Loss : 0.00015488696339379724\n",
      "Epoch 6500, Loss : 0.0001521595465508826\n",
      "Epoch 6600, Loss : 0.0001495233553305865\n",
      "Epoch 6700, Loss : 0.00014697395118908014\n",
      "Epoch 6800, Loss : 0.00014450717667843668\n",
      "Epoch 6900, Loss : 0.000142119133654748\n",
      "Epoch 7000, Loss : 0.00013980616347521218\n",
      "Epoch 7100, Loss : 0.00013756482897610693\n",
      "Epoch 7200, Loss : 0.00013539189804812697\n",
      "Epoch 7300, Loss : 0.00013328432864673107\n",
      "Epoch 7400, Loss : 0.00013123925509370853\n",
      "Epoch 7500, Loss : 0.0001292539755424366\n",
      "Epoch 7600, Loss : 0.00012732594049337905\n",
      "Epoch 7700, Loss : 0.0001254527422588505\n",
      "Epoch 7800, Loss : 0.00012363210528703152\n",
      "Epoch 7900, Loss : 0.00012186187726475427\n",
      "Epoch 8000, Loss : 0.00012014002092710659\n",
      "Epoch 8100, Loss : 0.00011846460650938751\n",
      "Epoch 8200, Loss : 0.00011683380478352225\n",
      "Epoch 8300, Loss : 0.00011524588062698506\n",
      "Epoch 8400, Loss : 0.00011369918707742436\n",
      "Epoch 8500, Loss : 0.0001121921598308356\n",
      "Epoch 8600, Loss : 0.000110723312145263\n",
      "Epoch 8700, Loss : 0.00010929123011567057\n",
      "Epoch 8800, Loss : 0.00010789456828888788\n",
      "Epoch 8900, Loss : 0.0001065320455905095\n",
      "Epoch 9000, Loss : 0.00010520244153821665\n",
      "Epoch 9100, Loss : 0.00010390459271835501\n",
      "Epoch 9200, Loss : 0.00010263738950470722\n",
      "Epoch 9300, Loss : 0.00010139977300033351\n",
      "Epoch 9400, Loss : 0.00010019073218499882\n",
      "Epoch 9500, Loss : 9.900930125231292e-05\n",
      "Epoch 9600, Loss : 9.785455712202243e-05\n",
      "Epoch 9700, Loss : 9.67256171142473e-05\n",
      "Epoch 9800, Loss : 9.562163677346872e-05\n",
      "Epoch 9900, Loss : 9.45418078312157e-05\n",
      "\n",
      "Prédictions après entraînement :\n",
      "Entrée : [0 0], Prediction : 0.0090, Attendu : 0\n",
      "Entrée : [0 1], Prediction : 0.9905, Attendu : 1\n",
      "Entrée : [1 0], Prediction : 0.9904, Attendu : 1\n",
      "Entrée : [1 1], Prediction : 0.0105, Attendu : 0\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": [
    "# Etape 7 : Test du modèle\n",
    "if __name__ == \"__main__\":\n",
    "    # Données XOR\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "    # Création et entraînement du MLP\n",
    "    mlp = MLP(input_size=2, hidden_size=4, output_size=1, learning_rate=2, seed=28)\n",
    "    losses = mlp.train(X, y, epochs=10000)\n",
    "\n",
    "    # Prédictions\n",
    "    predictions = mlp.forward(X)\n",
    "    print(\"\\nPrédictions après entraînement :\")\n",
    "    for i in range(len(X)):\n",
    "        print(f\"Entrée : {X[i]}, Prediction : {predictions[i][0]:.4f}, Attendu : {y[i][0]}\")\n",
    "        # Assertion : Verifier que les predictions sont coherentes avec XOR\n",
    "        if y[i][0] == 0:\n",
    "            assert predictions[i][0] < 0.5, f\"Prediction pour {X[i]} devrait être < 0.5\"\n",
    "        else:\n",
    "            assert predictions[i][0] > 0.5, f\"Prediction pour {X[i]} devrait être > 0.5\""
   ],
   "id": "96ceee20fb6c8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T07:49:21.175383Z",
     "start_time": "2025-05-06T07:49:19.490945Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7,
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Loss Function')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Loss Function vs Epochs')\n",
    "plt.show()"
   ],
   "id": "ff6f9a0ff19c34a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "On constate alors que notre modéle a été bien convergé avec des hyperparamatères de :\n",
    "* un taux d'apprentissage $ \\eta = 2 $\n",
    "* $ \\text{seed} = 28  $\n",
    "* et un nombre des $ \\text{ epochs} = 10000 $"
   ],
   "id": "a75e50a656e7ab26"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
